{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reverb.training.utils import DEFAULT_TRAINING_KWARGS, DEFAULT_MODEL_KWARGS, DEFAULT_DATA_KWARGS\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "supervised_experiments = {\n",
    "    \"baseline\": {\n",
    "        \"run_name\": \"ablations/supervised/baseline\",\n",
    "        \"training_kwargs\": {\n",
    "            \"max_epochs\": 20,\n",
    "        },\n",
    "        \"model_kwargs\": DEFAULT_MODEL_KWARGS,\n",
    "        \"data_kwargs\": DEFAULT_DATA_KWARGS,\n",
    "    },\n",
    "    \"bs64\": {\n",
    "        \"run_name\": \"ablations/supervised/bs64\",\n",
    "        \"training_kwargs\": {\n",
    "            \"max_epochs\": 25,\n",
    "            \"batch_size\": 64,   \n",
    "        },\n",
    "        \"model_kwargs\": DEFAULT_MODEL_KWARGS,\n",
    "        \"data_kwargs\": DEFAULT_DATA_KWARGS,\n",
    "    },\n",
    "    \"class_weight_0.1\": {\n",
    "        \"run_name\": \"ablations/supervised/class_weight_0.1\",\n",
    "        \"training_kwargs\": {\n",
    "            \"max_epochs\": 20,\n",
    "            \"class_weights\": [0.1, 1.0]\n",
    "        },\n",
    "        \"model_kwargs\": DEFAULT_MODEL_KWARGS,\n",
    "        \"data_kwargs\": DEFAULT_DATA_KWARGS,\n",
    "    },\n",
    "    \"class_weight_1.0\": {\n",
    "        \"run_name\": \"ablations/supervised/class_weight_1.0\",\n",
    "        \"training_kwargs\": {\n",
    "            \"max_epochs\": 20,\n",
    "            \"class_weights\": [1.0, 1.0]\n",
    "        },\n",
    "        \"model_kwargs\": DEFAULT_MODEL_KWARGS,\n",
    "        \"data_kwargs\": DEFAULT_DATA_KWARGS,\n",
    "    },\n",
    "    \"unetpp\": {\n",
    "        \"run_name\": \"ablations/supervised/unetpp\",\n",
    "        \"training_kwargs\": {\n",
    "            \"max_epochs\": 25,\n",
    "        },\n",
    "        \"model_kwargs\": {\n",
    "            \"model_type\": smp.UnetPlusPlus,\n",
    "            \"encoder_name\": \"resnet18\",\n",
    "            \"encoder_weights\": \"imagenet\",\n",
    "        },\n",
    "        \"data_kwargs\": DEFAULT_DATA_KWARGS,\n",
    "    },\n",
    "    \"no_imagenet\": {\n",
    "        \"run_name\": \"ablations/supervised/no_imagenet\",\n",
    "        \"training_kwargs\": {\n",
    "            \"max_epochs\": 30,\n",
    "        },\n",
    "        \"model_kwargs\": {\n",
    "            \"encoder_name\": \"resnet18\",\n",
    "            \"encoder_weights\": None,\n",
    "        },\n",
    "        \"data_kwargs\": DEFAULT_DATA_KWARGS,\n",
    "    },\n",
    "    \"resnet50\": {\n",
    "        \"run_name\": \"ablations/supervised/resnet50\",\n",
    "        \"training_kwargs\": {\n",
    "            \"max_epochs\": 30,\n",
    "        },\n",
    "        \"model_kwargs\": {\n",
    "            \"encoder_name\": \"resnet50\",\n",
    "            \"encoder_weights\": \"imagenet\",\n",
    "        },\n",
    "        \"data_kwargs\": DEFAULT_DATA_KWARGS,\n",
    "    },\n",
    "    \"resnet101\": {\n",
    "        \"run_name\": \"ablations/supervised/resnet101\",\n",
    "        \"training_kwargs\": {\n",
    "            \"max_epochs\": 30,\n",
    "        },\n",
    "        \"model_kwargs\": {\n",
    "            \"encoder_name\": \"resnet101\",\n",
    "            \"encoder_weights\": \"imagenet\",\n",
    "        },\n",
    "        \"data_kwargs\": DEFAULT_DATA_KWARGS,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from reverb.training.utils import train, get_eval_dataloaders, compute_results_over_eval_sets, save_evaluation_results\n",
    "eval_dataloaders = get_eval_dataloaders()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'supervised_experiments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m experiment \u001b[38;5;129;01min\u001b[39;00m \u001b[43msupervised_experiments\u001b[49m\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      2\u001b[0m     experiment_config \u001b[38;5;241m=\u001b[39m supervised_experiments[experiment]\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'supervised_experiments' is not defined"
     ]
    }
   ],
   "source": [
    "for experiment in supervised_experiments.keys():\n",
    "    experiment_config = supervised_experiments[experiment]\n",
    "    for i in range(3):\n",
    "        run_name = f\"{experiment_config['run_name']}_{i}\"\n",
    "\n",
    "        training_kwargs = experiment_config['training_kwargs']\n",
    "        model_kwargs = experiment_config['model_kwargs']\n",
    "        data_kwargs = experiment_config['data_kwargs']\n",
    "        # Train the model\n",
    "        train(\n",
    "            run_name=run_name,\n",
    "            mode=\"supervised\",\n",
    "            model_kwargs=model_kwargs,\n",
    "            data_kwargs=data_kwargs,  \n",
    "            training_kwargs=training_kwargs,\n",
    "        )\n",
    "\n",
    "        # Evaluate the model\n",
    "        results = compute_results_over_eval_sets(run_name, eval_dataloaders, model_kwargs=model_kwargs)\n",
    "        save_evaluation_results(run_name, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved individual repeat results and summary statistics.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "experiment_names = supervised_experiments.keys()\n",
    "\n",
    "# Root directory containing experiment folders like 'baseline_model_0/', 'baseline_model_1/', etc.\n",
    "experiments_root = './checkpoints/ablations/supervised'\n",
    "\n",
    "flattened_data = []\n",
    "\n",
    "for exp_name in experiment_names:\n",
    "    # Find folders starting with the experiment name and ending in a number (repeats)\n",
    "    matching_folders = [\n",
    "        d for d in os.listdir(experiments_root)\n",
    "        if os.path.isdir(os.path.join(experiments_root, d)) and d.startswith(exp_name + '_')\n",
    "    ]\n",
    "\n",
    "    for folder in matching_folders:\n",
    "        results_path = os.path.join(experiments_root, folder, 'eval_results.json')\n",
    "        if os.path.isfile(results_path):\n",
    "            with open(results_path, 'r') as f:\n",
    "                datasets = json.load(f)\n",
    "            for dataset, metrics in datasets.items():\n",
    "                for metric, value in metrics.items():\n",
    "                    if metric in ['miou', 'precision', 'recall']:\n",
    "                        flattened_data.append({\n",
    "                            'Experiment': exp_name,  # Group under common experiment name\n",
    "                            'Repeat': folder,\n",
    "                            'Dataset': dataset,\n",
    "                            'Metric': metric,\n",
    "                            'Value': value\n",
    "                        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Compute mean and SEM over repeats for each experiment\n",
    "mean_df = (\n",
    "    df.groupby(['Experiment', 'Dataset', 'Metric'])['Value']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'Value': 'Mean'})\n",
    ")\n",
    "\n",
    "sem_df = (\n",
    "    df.groupby(['Experiment', 'Dataset', 'Metric'])['Value']\n",
    "    .sem()\n",
    "    .reset_index()\n",
    "    .rename(columns={'Value': 'Std_Error'})\n",
    ")\n",
    "\n",
    "# Merge summaries\n",
    "summary_df = pd.merge(mean_df, sem_df, on=['Experiment', 'Dataset', 'Metric'])\n",
    "\n",
    "# Save outputs\n",
    "df.to_csv('individual_repeat_results.csv', index=False)\n",
    "summary_df.to_csv('supervised_experiment_summary.csv', index=False)\n",
    "\n",
    "print(\"Saved individual repeat results and summary statistics.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dataset: rr_eval ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>rr_eval</td>\n",
       "      <td>0.515835</td>\n",
       "      <td>0.008360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bs64</td>\n",
       "      <td>rr_eval</td>\n",
       "      <td>0.372996</td>\n",
       "      <td>0.059421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>class_weight_0.1</td>\n",
       "      <td>rr_eval</td>\n",
       "      <td>0.363139</td>\n",
       "      <td>0.013980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>class_weight_1.0</td>\n",
       "      <td>rr_eval</td>\n",
       "      <td>0.473995</td>\n",
       "      <td>0.020258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>no_imagenet</td>\n",
       "      <td>rr_eval</td>\n",
       "      <td>0.484657</td>\n",
       "      <td>0.024188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>rr_eval</td>\n",
       "      <td>0.502370</td>\n",
       "      <td>0.002264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>unetpp</td>\n",
       "      <td>rr_eval</td>\n",
       "      <td>0.469051</td>\n",
       "      <td>0.009271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Experiment  Dataset      Mean  Std_Error\n",
       "0           baseline  rr_eval  0.515835   0.008360\n",
       "9               bs64  rr_eval  0.372996   0.059421\n",
       "18  class_weight_0.1  rr_eval  0.363139   0.013980\n",
       "27  class_weight_1.0  rr_eval  0.473995   0.020258\n",
       "36       no_imagenet  rr_eval  0.484657   0.024188\n",
       "45          resnet50  rr_eval  0.502370   0.002264\n",
       "54            unetpp  rr_eval  0.469051   0.009271"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dataset: up34_eval ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline</td>\n",
       "      <td>up34_eval</td>\n",
       "      <td>0.493216</td>\n",
       "      <td>0.016052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bs64</td>\n",
       "      <td>up34_eval</td>\n",
       "      <td>0.403132</td>\n",
       "      <td>0.023373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>class_weight_0.1</td>\n",
       "      <td>up34_eval</td>\n",
       "      <td>0.269367</td>\n",
       "      <td>0.008173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>class_weight_1.0</td>\n",
       "      <td>up34_eval</td>\n",
       "      <td>0.515146</td>\n",
       "      <td>0.014166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>no_imagenet</td>\n",
       "      <td>up34_eval</td>\n",
       "      <td>0.521609</td>\n",
       "      <td>0.008068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>up34_eval</td>\n",
       "      <td>0.530767</td>\n",
       "      <td>0.005630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>unetpp</td>\n",
       "      <td>up34_eval</td>\n",
       "      <td>0.446338</td>\n",
       "      <td>0.023234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Experiment    Dataset      Mean  Std_Error\n",
       "3           baseline  up34_eval  0.493216   0.016052\n",
       "12              bs64  up34_eval  0.403132   0.023373\n",
       "21  class_weight_0.1  up34_eval  0.269367   0.008173\n",
       "30  class_weight_1.0  up34_eval  0.515146   0.014166\n",
       "39       no_imagenet  up34_eval  0.521609   0.008068\n",
       "48          resnet50  up34_eval  0.530767   0.005630\n",
       "57            unetpp  up34_eval  0.446338   0.023234"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dataset: valid ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>baseline</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.416180</td>\n",
       "      <td>0.002065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bs64</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.345951</td>\n",
       "      <td>0.014573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>class_weight_0.1</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.317233</td>\n",
       "      <td>0.002798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>class_weight_1.0</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.393538</td>\n",
       "      <td>0.009941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>no_imagenet</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.420683</td>\n",
       "      <td>0.005143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>resnet50</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.420352</td>\n",
       "      <td>0.005390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>unetpp</td>\n",
       "      <td>valid</td>\n",
       "      <td>0.405168</td>\n",
       "      <td>0.007725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Experiment Dataset      Mean  Std_Error\n",
       "6           baseline   valid  0.416180   0.002065\n",
       "15              bs64   valid  0.345951   0.014573\n",
       "24  class_weight_0.1   valid  0.317233   0.002798\n",
       "33  class_weight_1.0   valid  0.393538   0.009941\n",
       "42       no_imagenet   valid  0.420683   0.005143\n",
       "51          resnet50   valid  0.420352   0.005390\n",
       "60            unetpp   valid  0.405168   0.007725"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter only for 'miou'\n",
    "miou_df = summary_df[summary_df['Metric'] == 'miou']\n",
    "\n",
    "# Print one table per dataset\n",
    "for dataset in miou_df['Dataset'].unique():\n",
    "    print(f\"\\n--- Dataset: {dataset} ---\")\n",
    "    display(miou_df[miou_df['Dataset'] == dataset].drop(columns=['Metric']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_pds = []\n",
    "approaches = ['supervised', 'semisupervised', 'synthetic', 'multiclass']\n",
    "for approach in approaches:\n",
    "    # Load the summary DataFrame for the current approach\n",
    "    df = pd.read_csv(f'{approach}_experiment_summary.csv')\n",
    "    df[\"Approach\"] = approach\n",
    "    # Filter only for 'miou'\n",
    "    \n",
    "    all_pds.append(df)\n",
    "all_pds = pd.concat(all_pds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_round(val, primary=2, fallback=3):\n",
    "    \"\"\"Round to `primary` digits unless it would round to 0.0, then use `fallback`.\"\"\"\n",
    "    rounded = val.round(primary)\n",
    "    fallback_rounded = val.round(fallback)\n",
    "    # Where the primary rounding produces 0.0 but fallback doesnâ€™t\n",
    "    mask = (rounded == 0) & (fallback_rounded != 0)\n",
    "    return rounded.where(~mask, fallback_rounded)\n",
    "\n",
    "\n",
    "def generate_combined_latex_table(df, dataset_rename, metric_order=[\"miou\", \"recall\"], rename_map={}):\n",
    "    import pandas as pd\n",
    "\n",
    "    # Filter relevant metrics\n",
    "    df = df[df[\"Metric\"].isin(metric_order)]\n",
    "\n",
    "    # Define column ordering\n",
    "    dataset_order = list(dataset_rename.keys())\n",
    "    col_order = [(ds, m) for ds in dataset_order for m in metric_order]\n",
    "\n",
    "    # Pivot full table\n",
    "    pivot = df.pivot_table(\n",
    "        index=[\"Approach\", \"Experiment\"],\n",
    "        columns=[\"Dataset\", \"Metric\"],\n",
    "        values=[\"Mean\", \"Std_Error\"]\n",
    "    )\n",
    "\n",
    "    # Format values as \\SI\n",
    "    formatted = pd.DataFrame(index=pivot.index)\n",
    "    for (stat_type, dataset, metric) in pivot.columns:\n",
    "        if stat_type == \"Mean\":\n",
    "            mean = pivot[\"Mean\"][(dataset, metric)]\n",
    "            std = pivot[\"Std_Error\"][(dataset, metric)]\n",
    "            colname = (dataset, metric)\n",
    "            mean_rounded = smart_round(mean)\n",
    "            std_rounded = smart_round(std)\n",
    "\n",
    "            formatted[colname] = (\n",
    "                \"\\\\SI[mode=text]{\"\n",
    "                + mean_rounded.astype(str)\n",
    "                + \" \\\\pm \"\n",
    "                + std_rounded.astype(str)\n",
    "                + \"}{}\"\n",
    "            )\n",
    "\n",
    "    # Ensure column order\n",
    "    formatted = formatted[[col for col in col_order if col in formatted.columns]]\n",
    "\n",
    "    # Build headers\n",
    "    header1 = [\"Model Type\"]\n",
    "    header2 = [\"Experiment\"]\n",
    "    for ds in dataset_order:\n",
    "        label = dataset_rename[ds]\n",
    "        header1 += [f\"\\\\multicolumn{{{len(metric_order)}}}{{c}}{{{label}}}\"]\n",
    "        header2 += metric_order\n",
    "\n",
    "    # Build rows with grouped approaches\n",
    "    rows = []\n",
    "    for approach in formatted.index.get_level_values(0).unique():\n",
    "        rows.append(\"\\\\midrule\")\n",
    "        rows.append(f\"\\\\multicolumn{{{1 + len(col_order)}}}{{l}}{{\\\\textbf{{{approach}}}}} \\\\\\\\\")\n",
    "        for experiment in formatted.loc[approach].index:\n",
    "            values = formatted.loc[(approach, experiment)]\n",
    "            row_label = rename_map.get((approach, experiment), experiment)\n",
    "            row = [row_label] + [values.get(col, \"\") for col in col_order]\n",
    "\n",
    "            rows.append(\" & \".join(row) + \" \\\\\\\\\")\n",
    "\n",
    "    # Construct LaTeX table\n",
    "    ncols = 1 + len(col_order)\n",
    "    col_spec = \"l\" + \"c\" * (ncols - 1)\n",
    "    latex = \"\\n\".join([\n",
    "        \"\\\\begin{tabular}{\" + col_spec + \"}\",\n",
    "        \"\\\\toprule\",\n",
    "        \" & \".join(header1) + \" \\\\\\\\\",\n",
    "        \" & \".join(header2) + \" \\\\\\\\\",\n",
    "        \"\\n\".join(rows),\n",
    "        \"\\\\bottomrule\",\n",
    "        \"\\\\end{tabular}\"\n",
    "    ])\n",
    "\n",
    "    return latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rename_map = {\n",
      "    ('multiclass', 'baseline'): '',\n",
      "    ('semisupervised', 'alpha_0.9'): '',\n",
      "    ('semisupervised', 'alpha_0.98'): '',\n",
      "    ('semisupervised', 'alpha_0.999'): '',\n",
      "    ('semisupervised', 'baseline'): '',\n",
      "    ('semisupervised', 'lambda_0.1'): '',\n",
      "    ('semisupervised', 'lambda_2.0'): '',\n",
      "    ('semisupervised', 'no_ramp_up'): '',\n",
      "    ('supervised', 'baseline'): '',\n",
      "    ('supervised', 'bs64'): '',\n",
      "    ('supervised', 'class_weight_0.1'): '',\n",
      "    ('supervised', 'class_weight_1.0'): '',\n",
      "    ('supervised', 'no_imagenet'): '',\n",
      "    ('supervised', 'resnet50'): '',\n",
      "    ('supervised', 'unetpp'): '',\n",
      "    ('synthetic', 'baseline'): '',\n",
      "    ('synthetic', 'long_pretrain'): '',\n",
      "    ('synthetic', 'long_pretrain_bs128'): '',\n",
      "    ('synthetic', 'no_pre'): '',\n",
      "    ('synthetic', 'no_weight_decay_all'): '',\n",
      "    ('synthetic', 'no_weight_decay_fine'): '',\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "unique_pairs = all_pds[[\"Approach\", \"Experiment\"]].drop_duplicates().sort_values(by=[\"Approach\", \"Experiment\"])\n",
    "\n",
    "# Generate dictionary definition\n",
    "print(\"rename_map = {\")\n",
    "for _, row in unique_pairs.iterrows():\n",
    "    print(f\"    ({row['Approach']!r}, {row['Experiment']!r}): '',\")\n",
    "print(\"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lcccccc}\n",
      "\\toprule\n",
      "Model Type & \\multicolumn{2}{c}{UP05 Validation Set} & \\multicolumn{2}{c}{UPFLOW UP34} & \\multicolumn{2}{c}{RHUM-RUM RR40} \\\\\n",
      "Experiment & miou & recall & miou & recall & miou & recall \\\\\n",
      "\\midrule\n",
      "\\multicolumn{7}{l}{\\textbf{multiclass}} \\\\\n",
      "Multiclass Baseline & \\SI[mode=text]{0.41 \\pm 0.004}{} & \\SI[mode=text]{0.53 \\pm 0.03}{} & \\SI[mode=text]{0.49 \\pm 0.01}{} & \\SI[mode=text]{0.75 \\pm 0.03}{} & \\SI[mode=text]{0.48 \\pm 0.01}{} & \\SI[mode=text]{0.61 \\pm 0.04}{} \\\\\n",
      "\\midrule\n",
      "\\multicolumn{7}{l}{\\textbf{semisupervised}} \\\\\n",
      "$\\alpha=0.9$ & \\SI[mode=text]{0.43 \\pm 0.002}{} & \\SI[mode=text]{0.56 \\pm 0.01}{} & \\SI[mode=text]{0.52 \\pm 0.002}{} & \\SI[mode=text]{0.8 \\pm 0.03}{} & \\SI[mode=text]{0.45 \\pm 0.01}{} & \\SI[mode=text]{0.58 \\pm 0.04}{} \\\\\n",
      "Baseline & \\SI[mode=text]{0.43 \\pm 0.002}{} & \\SI[mode=text]{0.59 \\pm 0.01}{} & \\SI[mode=text]{0.47 \\pm 0.01}{} & \\SI[mode=text]{0.85 \\pm 0.01}{} & \\SI[mode=text]{0.5 \\pm 0.02}{} & \\SI[mode=text]{0.72 \\pm 0.06}{} \\\\\n",
      "$\\alpha=0.999$ & \\SI[mode=text]{0.22 \\pm 0.06}{} & \\SI[mode=text]{0.23 \\pm 0.07}{} & \\SI[mode=text]{0.31 \\pm 0.06}{} & \\SI[mode=text]{0.33 \\pm 0.07}{} & \\SI[mode=text]{0.31 \\pm 0.04}{} & \\SI[mode=text]{0.32 \\pm 0.04}{} \\\\\n",
      "$\\alpha=0.995$ & \\SI[mode=text]{0.43 \\pm 0.001}{} & \\SI[mode=text]{0.61 \\pm 0.01}{} & \\SI[mode=text]{0.46 \\pm 0.01}{} & \\SI[mode=text]{0.84 \\pm 0.02}{} & \\SI[mode=text]{0.5 \\pm 0.002}{} & \\SI[mode=text]{0.72 \\pm 0.04}{} \\\\\n",
      "$\\lambda_{\\textrm{cons}}=0.1$ & \\SI[mode=text]{0.43 \\pm 0.01}{} & \\SI[mode=text]{0.59 \\pm 0.02}{} & \\SI[mode=text]{0.49 \\pm 0.02}{} & \\SI[mode=text]{0.79 \\pm 0.03}{} & \\SI[mode=text]{0.45 \\pm 0.01}{} & \\SI[mode=text]{0.56 \\pm 0.01}{} \\\\\n",
      "$\\lambda_{\\textrm{cons}}=2.0$ & \\SI[mode=text]{0.43 \\pm 0.01}{} & \\SI[mode=text]{0.58 \\pm 0.02}{} & \\SI[mode=text]{0.47 \\pm 0.01}{} & \\SI[mode=text]{0.83 \\pm 0.01}{} & \\SI[mode=text]{0.45 \\pm 0.003}{} & \\SI[mode=text]{0.55 \\pm 0.01}{} \\\\\n",
      "No $\\lambda_{\\textrm{cons}}$ Ramp Up & \\SI[mode=text]{0.43 \\pm 0.003}{} & \\SI[mode=text]{0.6 \\pm 0.002}{} & \\SI[mode=text]{0.47 \\pm 0.03}{} & \\SI[mode=text]{0.83 \\pm 0.01}{} & \\SI[mode=text]{0.46 \\pm 0.03}{} & \\SI[mode=text]{0.59 \\pm 0.04}{} \\\\\n",
      "\\midrule\n",
      "\\multicolumn{7}{l}{\\textbf{supervised}} \\\\\n",
      "Baseline & \\SI[mode=text]{0.42 \\pm 0.002}{} & \\SI[mode=text]{0.57 \\pm 0.02}{} & \\SI[mode=text]{0.49 \\pm 0.02}{} & \\SI[mode=text]{0.81 \\pm 0.02}{} & \\SI[mode=text]{0.52 \\pm 0.01}{} & \\SI[mode=text]{0.73 \\pm 0.04}{} \\\\\n",
      "Batch size 64 & \\SI[mode=text]{0.35 \\pm 0.01}{} & \\SI[mode=text]{0.47 \\pm 0.03}{} & \\SI[mode=text]{0.4 \\pm 0.02}{} & \\SI[mode=text]{0.64 \\pm 0.01}{} & \\SI[mode=text]{0.37 \\pm 0.06}{} & \\SI[mode=text]{0.58 \\pm 0.04}{} \\\\\n",
      "Class weight $w=0.1$ & \\SI[mode=text]{0.32 \\pm 0.003}{} & \\SI[mode=text]{0.8 \\pm 0.0}{} & \\SI[mode=text]{0.27 \\pm 0.01}{} & \\SI[mode=text]{0.94 \\pm 0.01}{} & \\SI[mode=text]{0.36 \\pm 0.01}{} & \\SI[mode=text]{0.85 \\pm 0.01}{} \\\\\n",
      "Class weight $w=1.0$ & \\SI[mode=text]{0.39 \\pm 0.01}{} & \\SI[mode=text]{0.46 \\pm 0.02}{} & \\SI[mode=text]{0.52 \\pm 0.01}{} & \\SI[mode=text]{0.65 \\pm 0.02}{} & \\SI[mode=text]{0.47 \\pm 0.02}{} & \\SI[mode=text]{0.56 \\pm 0.04}{} \\\\\n",
      "No ImageNet weights & \\SI[mode=text]{0.42 \\pm 0.01}{} & \\SI[mode=text]{0.54 \\pm 0.02}{} & \\SI[mode=text]{0.52 \\pm 0.01}{} & \\SI[mode=text]{0.76 \\pm 0.02}{} & \\SI[mode=text]{0.48 \\pm 0.02}{} & \\SI[mode=text]{0.63 \\pm 0.06}{} \\\\\n",
      "Resnet50 encoder & \\SI[mode=text]{0.42 \\pm 0.01}{} & \\SI[mode=text]{0.54 \\pm 0.03}{} & \\SI[mode=text]{0.53 \\pm 0.01}{} & \\SI[mode=text]{0.78 \\pm 0.03}{} & \\SI[mode=text]{0.5 \\pm 0.002}{} & \\SI[mode=text]{0.65 \\pm 0.04}{} \\\\\n",
      "U-net++ decoder & \\SI[mode=text]{0.41 \\pm 0.01}{} & \\SI[mode=text]{0.61 \\pm 0.03}{} & \\SI[mode=text]{0.45 \\pm 0.02}{} & \\SI[mode=text]{0.81 \\pm 0.03}{} & \\SI[mode=text]{0.47 \\pm 0.01}{} & \\SI[mode=text]{0.65 \\pm 0.03}{} \\\\\n",
      "\\midrule\n",
      "\\multicolumn{7}{l}{\\textbf{synthetic}} \\\\\n",
      "Baseline & \\SI[mode=text]{0.44 \\pm 0.002}{} & \\SI[mode=text]{0.6 \\pm 0.01}{} & \\SI[mode=text]{0.53 \\pm 0.01}{} & \\SI[mode=text]{0.83 \\pm 0.01}{} & \\SI[mode=text]{0.49 \\pm 0.01}{} & \\SI[mode=text]{0.7 \\pm 0.02}{} \\\\\n",
      "20k spectrogram pretraining & \\SI[mode=text]{0.43 \\pm 0.01}{} & \\SI[mode=text]{0.58 \\pm 0.02}{} & \\SI[mode=text]{0.52 \\pm 0.01}{} & \\SI[mode=text]{0.8 \\pm 0.03}{} & \\SI[mode=text]{0.48 \\pm 0.01}{} & \\SI[mode=text]{0.68 \\pm 0.04}{} \\\\\n",
      "Batch size 128 pretraining & \\SI[mode=text]{0.41 \\pm 0.01}{} & \\SI[mode=text]{0.57 \\pm 0.04}{} & \\SI[mode=text]{0.49 \\pm 0.003}{} & \\SI[mode=text]{0.75 \\pm 0.03}{} & \\SI[mode=text]{0.45 \\pm 0.01}{} & \\SI[mode=text]{0.59 \\pm 0.03}{} \\\\\n",
      "No ImageNet weights & \\SI[mode=text]{0.44 \\pm 0.002}{} & \\SI[mode=text]{0.6 \\pm 0.01}{} & \\SI[mode=text]{0.52 \\pm 0.01}{} & \\SI[mode=text]{0.85 \\pm 0.01}{} & \\SI[mode=text]{0.49 \\pm 0.004}{} & \\SI[mode=text]{0.72 \\pm 0.02}{} \\\\\n",
      "No weight decay & \\SI[mode=text]{0.43 \\pm 0.002}{} & \\SI[mode=text]{0.61 \\pm 0.01}{} & \\SI[mode=text]{0.51 \\pm 0.01}{} & \\SI[mode=text]{0.84 \\pm 0.01}{} & \\SI[mode=text]{0.46 \\pm 0.001}{} & \\SI[mode=text]{0.67 \\pm 0.02}{} \\\\\n",
      "Only weight decay pretraining & \\SI[mode=text]{0.44 \\pm 0.001}{} & \\SI[mode=text]{0.61 \\pm 0.01}{} & \\SI[mode=text]{0.52 \\pm 0.01}{} & \\SI[mode=text]{0.83 \\pm 0.01}{} & \\SI[mode=text]{0.49 \\pm 0.01}{} & \\SI[mode=text]{0.7 \\pm 0.01}{} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# Define how you'd like the datasets to appear\n",
    "dataset_rename = {\n",
    "    \"valid\": \"UP05 Validation Set\",\n",
    "    \"up34_eval\": \"UPFLOW UP34\",\n",
    "    \"rr_eval\": \"RHUM-RUM RR40\"\n",
    "}\n",
    "rename_map = rename_map = {\n",
    "    ('multiclass', 'baseline'): 'Multiclass Baseline',\n",
    "    ('semisupervised', 'alpha_0.9'): r'$\\alpha=0.9$',\n",
    "    ('semisupervised', 'alpha_0.98'): 'Baseline',\n",
    "    ('semisupervised', 'alpha_0.999'): r'$\\alpha=0.999$',\n",
    "    ('semisupervised', 'baseline'): r'$\\alpha=0.995$',\n",
    "    ('semisupervised', 'lambda_0.1'): r'$\\lambda_{\\textrm{cons}}=0.1$',\n",
    "    ('semisupervised', 'lambda_2.0'): r'$\\lambda_{\\textrm{cons}}=2.0$',\n",
    "    ('semisupervised', 'no_ramp_up'): r'No $\\lambda_{\\textrm{cons}}$ Ramp Up',\n",
    "    ('supervised', 'baseline'): 'Baseline',\n",
    "    ('supervised', 'bs64'): 'Batch size 64',\n",
    "    ('supervised', 'class_weight_0.1'): r'Class weight $w=0.1$',\n",
    "    ('supervised', 'class_weight_1.0'): r'Class weight $w=1.0$',\n",
    "    ('supervised', 'no_imagenet'): 'No ImageNet weights',\n",
    "    ('supervised', 'resnet50'): 'Resnet50 encoder',\n",
    "    ('supervised', 'unetpp'): 'U-net++ decoder',\n",
    "    ('synthetic', 'baseline'): 'Baseline',\n",
    "    ('synthetic', 'long_pretrain'): '20k spectrogram pretraining',\n",
    "    ('synthetic', 'long_pretrain_bs128'): 'Batch size 128 pretraining',\n",
    "    ('synthetic', 'no_pre'): 'No ImageNet weights',\n",
    "    ('synthetic', 'no_weight_decay_all'): 'No weight decay',\n",
    "    ('synthetic', 'no_weight_decay_fine'): 'Only weight decay pretraining',\n",
    "}\n",
    "\n",
    "latex = generate_combined_latex_table(all_pds, dataset_rename, rename_map=rename_map)\n",
    "print(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reverb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
