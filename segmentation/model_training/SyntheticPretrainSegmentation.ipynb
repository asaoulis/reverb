{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reverb.training.utils import DEFAULT_TRAINING_KWARGS, DEFAULT_MODEL_KWARGS, DEFAULT_DATA_KWARGS\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "synthetic_pretrain_experiments = {\n",
    "    \"baseline\": {\n",
    "        \"run_name\": \"ablations/synthetic/baseline\",\n",
    "        \"pretraining_kwargs\": {\n",
    "            \"max_epochs\": 50,\n",
    "        },\n",
    "        \"finetuning_kwargs\": {\n",
    "            \"max_epochs\": 12,   \n",
    "            \"lr\": 1e-5,\n",
    "            # \"weight_decay\": 0.0,\n",
    "        },\n",
    "        \"model_kwargs\": DEFAULT_MODEL_KWARGS,\n",
    "        \"data_kwargs\": DEFAULT_DATA_KWARGS,\n",
    "    },\n",
    "    \"no_weight_decay_all\": {\n",
    "        \"run_name\": \"ablations/synthetic/no_weight_decay_all\",\n",
    "        \"pretraining_kwargs\": {\n",
    "            \"max_epochs\": 50,\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "        \"finetuning_kwargs\": {\n",
    "            \"max_epochs\": 12,\n",
    "            \"lr\": 1e-5,\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "        \"model_kwargs\": DEFAULT_MODEL_KWARGS,\n",
    "        \"data_kwargs\": DEFAULT_DATA_KWARGS,\n",
    "    },\n",
    "    \"no_weight_decay_fine\": {\n",
    "        \"run_name\": \"ablations/synthetic/no_weight_decay_fine\",\n",
    "        \"pretraining_kwargs\": {\n",
    "            \"max_epochs\": 50,\n",
    "        },\n",
    "        \"finetuning_kwargs\": {\n",
    "            \"max_epochs\": 12,\n",
    "            \"lr\": 1e-5,\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "        \"model_kwargs\": DEFAULT_MODEL_KWARGS,\n",
    "        \"data_kwargs\": DEFAULT_DATA_KWARGS,\n",
    "    },\n",
    "    \"no_pre\": {\n",
    "        \"run_name\": \"ablations/synthetic/no_pre\",\n",
    "        \"pretraining_kwargs\": {\n",
    "            \"max_epochs\": 50,\n",
    "        },\n",
    "        \"finetuning_kwargs\": {\n",
    "            \"max_epochs\": 10,\n",
    "            \"lr\": 1e-5,\n",
    "            # \"weight_decay\": 0.0,\n",
    "        },\n",
    "        \"model_kwargs\": {\n",
    "            \"encoder_name\": \"resnet18\",\n",
    "            \"encoder_weights\": None,\n",
    "        },\n",
    "        \"data_kwargs\": DEFAULT_DATA_KWARGS,\n",
    "    },\n",
    "    \"long_pretrain\": {\n",
    "        \"run_name\": \"ablations/synthetic/long_pretrain\",\n",
    "        \"pretraining_kwargs\": {\n",
    "            \"max_epochs\": 100,\n",
    "        },\n",
    "        \"finetuning_kwargs\": {\n",
    "            \"max_epochs\": 12,   \n",
    "            \"lr\": 1e-5,\n",
    "            # \"weight_decay\": 0.0,\n",
    "        },\n",
    "        \"model_kwargs\": DEFAULT_MODEL_KWARGS,\n",
    "        \"data_kwargs\": DEFAULT_DATA_KWARGS,\n",
    "    \n",
    "    },\n",
    "    \"long_pretrain_bs128\": {\n",
    "        \"run_name\": \"ablations/synthetic/long_pretrain_bs128\",\n",
    "        \"pretraining_kwargs\": {\n",
    "            \"max_epochs\": 100,\n",
    "            \"batch_size\": 128,\n",
    "\n",
    "        },\n",
    "        \"finetuning_kwargs\": {\n",
    "            \"max_epochs\": 12,   \n",
    "            \"lr\": 1e-5,\n",
    "            # \"weight_decay\": 0.0,\n",
    "        },\n",
    "        \"model_kwargs\": DEFAULT_MODEL_KWARGS,\n",
    "        \"data_kwargs\": DEFAULT_DATA_KWARGS,\n",
    "    \n",
    "    },\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reverb.training.utils import train, get_eval_dataloaders, compute_results_over_eval_sets, save_evaluation_results\n",
    "eval_dataloaders = get_eval_dataloaders()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in synthetic_pretrain_experiments.keys():\n",
    "    experiment_config = synthetic_pretrain_experiments[experiment]\n",
    "    for i in range(3):\n",
    "        pretrain_run_name = f\"{experiment_config['run_name']}_pre_{i}\"\n",
    "\n",
    "        training_kwargs = experiment_config['pretraining_kwargs']\n",
    "        model_kwargs = experiment_config['model_kwargs']\n",
    "        data_kwargs = experiment_config['data_kwargs']\n",
    "        # Pre-train the model\n",
    "        train(\n",
    "            run_name=pretrain_run_name,\n",
    "            mode=\"synthetic_pretrain\",\n",
    "            model_kwargs=model_kwargs,\n",
    "            data_kwargs=data_kwargs,  \n",
    "            training_kwargs=training_kwargs,\n",
    "        )\n",
    "\n",
    "        run_name = f\"{experiment_config['run_name']}_fine_{i}\"\n",
    "        training_kwargs = experiment_config['finetuning_kwargs']\n",
    "\n",
    "        train(\n",
    "            run_name=run_name,\n",
    "            mode=\"supervised\",\n",
    "            model_kwargs=model_kwargs,\n",
    "            data_kwargs=data_kwargs,  \n",
    "            training_kwargs=training_kwargs,\n",
    "            pretrain_path=pretrain_run_name,\n",
    "        )\n",
    "        # Evaluate the model\n",
    "        results = compute_results_over_eval_sets(run_name, eval_dataloaders, model_kwargs=model_kwargs)\n",
    "        save_evaluation_results(run_name, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved individual repeat results and summary statistics.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "experiment_names = synthetic_pretrain_experiments.keys()\n",
    "\n",
    "# Root directory containing experiment folders like 'baseline_model_0/', 'baseline_model_1/', etc.\n",
    "experiments_root = './checkpoints/ablations/synthetic'\n",
    "\n",
    "flattened_data = []\n",
    "\n",
    "for exp_name in experiment_names:\n",
    "    # Find folders starting with the experiment name and ending in a number (repeats)\n",
    "    matching_folders = [\n",
    "        d for d in os.listdir(experiments_root)\n",
    "        if os.path.isdir(os.path.join(experiments_root, d)) and d.startswith(exp_name + '_')\n",
    "    ]\n",
    "\n",
    "    for folder in matching_folders:\n",
    "        results_path = os.path.join(experiments_root, folder, 'eval_results.json')\n",
    "        if os.path.isfile(results_path):\n",
    "            with open(results_path, 'r') as f:\n",
    "                datasets = json.load(f)\n",
    "            for dataset, metrics in datasets.items():\n",
    "                for metric, value in metrics.items():\n",
    "                    if metric in ['miou', 'precision', 'recall']:\n",
    "                        flattened_data.append({\n",
    "                            'Experiment': exp_name,  # Group under common experiment name\n",
    "                            'Repeat': folder,\n",
    "                            'Dataset': dataset,\n",
    "                            'Metric': metric,\n",
    "                            'Value': value\n",
    "                        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Compute mean and SEM over repeats for each experiment\n",
    "mean_df = (\n",
    "    df.groupby(['Experiment', 'Dataset', 'Metric'])['Value']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'Value': 'Mean'})\n",
    ")\n",
    "\n",
    "sem_df = (\n",
    "    df.groupby(['Experiment', 'Dataset', 'Metric'])['Value']\n",
    "    .sem()\n",
    "    .reset_index()\n",
    "    .rename(columns={'Value': 'Std_Error'})\n",
    ")\n",
    "\n",
    "# Merge summaries\n",
    "summary_df = pd.merge(mean_df, sem_df, on=['Experiment', 'Dataset', 'Metric'])\n",
    "\n",
    "# Save outputs\n",
    "df.to_csv('individual_repeat_results.csv', index=False)\n",
    "summary_df.to_csv('synthetic_experiment_summary.csv', index=False)\n",
    "\n",
    "print(\"Saved individual repeat results and summary statistics.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only for 'miou'\n",
    "miou_df = summary_df[summary_df['Metric'] == 'miou']\n",
    "\n",
    "# Print one table per dataset\n",
    "for dataset in miou_df['Dataset'].unique():\n",
    "    print(f\"\\n--- Dataset: {dataset} ---\")\n",
    "    display(miou_df[miou_df['Dataset'] == dataset].drop(columns=['Metric']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reverb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
