{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reverb.training.utils import DEFAULT_TRAINING_KWARGS, DEFAULT_MODEL_KWARGS, DEFAULT_DATA_KWARGS\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "experiments = {\n",
    "    \"supervised\": {\n",
    "        \"run_name\": \"whale/supervised_cw0.1\",\n",
    "        \"training_kwargs\": {\n",
    "            \"max_epochs\": 60,\n",
    "            \"lr\": 0.0001,\n",
    "            'class_weights': [0.1, 1.0]\n",
    "        },\n",
    "        \"model_kwargs\": DEFAULT_MODEL_KWARGS,\n",
    "        \"data_kwargs\": {\"feature_class\": \"whale_truncated\"},\n",
    "    },\n",
    "    \"semi_supervised\": {\n",
    "        \"run_name\": \"whale/semi_supervised_cw0.1\",\n",
    "        \"training_kwargs\": {\n",
    "            \"max_epochs\": 60,\n",
    "            \"alpha\": 0.98,\n",
    "            \"lr\": 0.0001,\n",
    "            'class_weights': [0.1, 1.0],\n",
    "            'consistency_lambda': 0.1\n",
    "\n",
    "        },\n",
    "        \"model_kwargs\": DEFAULT_MODEL_KWARGS,\n",
    "        \"data_kwargs\": {\"feature_class\": \"whale_truncated\"},\n",
    "    },\n",
    "    \"synthetic_pretrain\": {\n",
    "        \"run_name\": \"whale/synthetic_pretrain\",\n",
    "        \"training_kwargs\": {\n",
    "            \"max_epochs\": 25,\n",
    "            \"lr\": 5e-5,\n",
    "            'class_weights': [0.1, 1.0],\n",
    "        },\n",
    "        \"finetuning_kwargs\": {\n",
    "            \"max_epochs\": 30,   \n",
    "            \"lr\": 5e-6,\n",
    "            'class_weights': [0.1, 1.0]\n",
    "        },\n",
    "        \"model_kwargs\": DEFAULT_MODEL_KWARGS,\n",
    "        \"data_kwargs\": {\"feature_class\": \"whale_truncated\"},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reverb.training.utils import train, get_eval_dataloaders, compute_results_over_eval_sets, save_evaluation_results\n",
    "eval_dataloaders = get_eval_dataloaders(feature_class=\"whale_truncated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in experiments.keys():\n",
    "    experiment_config = experiments[experiment]\n",
    "    for i in range(3):\n",
    "        run_name = f\"{experiment_config['run_name']}_{i}\"\n",
    "        if experiment == \"synthetic_pretrain\":\n",
    "            run_name += \"_pre\"\n",
    "\n",
    "        training_kwargs = experiment_config['training_kwargs']\n",
    "        model_kwargs = experiment_config['model_kwargs']\n",
    "        data_kwargs = experiment_config['data_kwargs']\n",
    "        # Train the model\n",
    "        train(\n",
    "            run_name=run_name,\n",
    "            mode=experiment,\n",
    "            model_kwargs=model_kwargs,\n",
    "            data_kwargs=data_kwargs,  \n",
    "            training_kwargs=training_kwargs,\n",
    "            background_dir=\"../analysis/results/UP05_predictions/no_whales\",\n",
    "\n",
    "        )\n",
    "        if experiment == \"synthetic_pretrain\":\n",
    "            # Fine-tune the model\n",
    "            finetuning_kwargs = experiment_config.get('finetuning_kwargs', {})\n",
    "            finetune_run_name = f\"{experiment_config['run_name']}_{i}\"\n",
    "            train(\n",
    "                run_name=finetune_run_name,\n",
    "                mode=\"supervised\",\n",
    "                model_kwargs=model_kwargs,\n",
    "                data_kwargs=data_kwargs,  \n",
    "                training_kwargs=finetuning_kwargs,\n",
    "                pretrain_path=run_name,\n",
    "            )\n",
    "            run_name = finetune_run_name\n",
    "\n",
    "        # Evaluate the model\n",
    "        results = compute_results_over_eval_sets(run_name, eval_dataloaders, model_kwargs=model_kwargs, threshold=0.8)\n",
    "        save_evaluation_results(run_name, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "experiment_names = experiments.keys()\n",
    "\n",
    "# Root directory containing experiment folders like 'baseline_model_0/', 'baseline_model_1/', etc.\n",
    "experiments_root = './checkpoints/whale'\n",
    "\n",
    "flattened_data = []\n",
    "\n",
    "for exp_name in experiment_names:\n",
    "    # Find folders starting with the experiment name and ending in a number (repeats)\n",
    "    matching_folders = [\n",
    "        d for d in os.listdir(experiments_root)\n",
    "        if os.path.isdir(os.path.join(experiments_root, d)) and d.startswith(exp_name + '_')\n",
    "    ]\n",
    "\n",
    "    for folder in matching_folders:\n",
    "        results_path = os.path.join(experiments_root, folder, 'eval_results.json')\n",
    "        if os.path.isfile(results_path):\n",
    "            with open(results_path, 'r') as f:\n",
    "                datasets = json.load(f)\n",
    "            for dataset, metrics in datasets.items():\n",
    "                for metric, value in metrics.items():\n",
    "                    if metric in ['miou', 'precision', 'recall']:\n",
    "                        flattened_data.append({\n",
    "                            'Experiment': exp_name,  # Group under common experiment name\n",
    "                            'Repeat': folder,\n",
    "                            'Dataset': dataset,\n",
    "                            'Metric': metric,\n",
    "                            'Value': value\n",
    "                        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Compute mean and SEM over repeats for each experiment\n",
    "mean_df = (\n",
    "    df.groupby(['Experiment', 'Dataset', 'Metric'])['Value']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'Value': 'Mean'})\n",
    ")\n",
    "\n",
    "sem_df = (\n",
    "    df.groupby(['Experiment', 'Dataset', 'Metric'])['Value']\n",
    "    .sem()\n",
    "    .reset_index()\n",
    "    .rename(columns={'Value': 'Std_Error'})\n",
    ")\n",
    "\n",
    "# Merge summaries\n",
    "summary_df = pd.merge(mean_df, sem_df, on=['Experiment', 'Dataset', 'Metric'])\n",
    "\n",
    "# Save outputs\n",
    "df.to_csv('individual_repeat_results.csv', index=False)\n",
    "summary_df.to_csv('supervised_experiment_summary.csv', index=False)\n",
    "\n",
    "print(\"Saved individual repeat results and summary statistics.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only for 'miou'\n",
    "miou_df = summary_df[summary_df['Metric'] == 'miou']\n",
    "\n",
    "# Print one table per dataset\n",
    "for dataset in miou_df['Dataset'].unique():\n",
    "    print(f\"\\n--- Dataset: {dataset} ---\")\n",
    "    display(miou_df[miou_df['Dataset'] == dataset].drop(columns=['Metric']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Filter for the validation dataset and metrics of interest\n",
    "filtered = summary_df[\n",
    "    (summary_df['Dataset'] == 'valid') &\n",
    "    (summary_df['Metric'].isin(['miou', 'precision', 'recall']))\n",
    "]\n",
    "\n",
    "# Pivot so that rows are experiments and columns are metrics\n",
    "pivot_df = filtered.pivot(index='Experiment', columns='Metric', values=['Mean', 'Std_Error'])\n",
    "\n",
    "# Desired order of metrics\n",
    "metrics_order = ['miou', 'precision', 'recall']\n",
    "rows = []\n",
    "\n",
    "for experiment in pivot_df.index:\n",
    "    row = [experiment]  # Start with experiment name\n",
    "    for metric in metrics_order:\n",
    "        mean = pivot_df.loc[experiment, ('Mean', metric)]\n",
    "        sem = pivot_df.loc[experiment, ('Std_Error', metric)]\n",
    "        formatted = f\"{mean:.3f} \\pm {sem:.3f}\"\n",
    "        row.append(formatted)\n",
    "    rows.append(row)\n",
    "\n",
    "# Column headers\n",
    "headers = ['Model Type', 'IoU', 'Precision', 'Recall']\n",
    "\n",
    "# Generate LaTeX table\n",
    "latex_table = tabulate(rows, headers=headers, tablefmt='latex_booktabs')\n",
    "\n",
    "# Full LaTeX table\n",
    "latex_full = f\"\"\"\n",
    "\\\\begin{{table}}\n",
    "\\\\centering\n",
    "\\\\small\n",
    "\\\\setlength{{\\\\tabcolsep}}{{4pt}}\n",
    "\\\\caption{{Blue whale call segmentation performance on the UP05 validation dataset. \n",
    "The mean performance and standard error over three independent training runs are reported for each metric.}}\n",
    "\\\\label{{tab:results_whales}}\n",
    "{latex_table}\n",
    "\\\\end{{table}}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reverb.training.utils import load_best_model_from_run\n",
    "models = {}\n",
    "for exp_name, exp_config in experiments.items():\n",
    "    model = load_best_model_from_run(\n",
    "        run_name=exp_config['run_name'] + '_2',  # Assuming we want the first repeat\n",
    "        model_kwargs=exp_config['model_kwargs'],\n",
    "        training_kwargs=exp_config['training_kwargs'],\n",
    "    )\n",
    "    models[exp_name] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "valid_dataloader = eval_dataloaders['valid']\n",
    "valid_dataset_batch = next(iter(valid_dataloader))\n",
    "all_pred_masks = {} \n",
    "\n",
    "for name, model in models.items():\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    threshold = 0.8 if 'synthetic' in name else 0.8\n",
    "    print(threshold)\n",
    "    with torch.no_grad():\n",
    "        eval_dataloader = valid_dataloader\n",
    "        for batch in eval_dataloader:\n",
    "            images, masks = batch\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            y_pred = model(images)\n",
    "            probs = F.softmax(y_pred, dim=1)  # shape: (B, 2, H, W)\n",
    "\n",
    "            # Get class 1 probability and apply threshold\n",
    "            class1_prob = probs[:, 1, :, :]  # shape: (B, H, W)\n",
    "            masks_pred = (class1_prob > threshold).long().cpu().numpy()\n",
    "    all_pred_masks[name] = masks_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find indices where true masks sum to non-zero\n",
    "non_zero_indices = valid_dataset_batch[1].sum(dim=(1, 2)) > 0\n",
    "# print the actual index values\n",
    "print(\"Indices with non-zero true masks:\", non_zero_indices.nonzero(as_tuple=True)[0].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set font size for all plots\n",
    "plt.rcParams.update({'font.size': 36})\n",
    "\n",
    "def apply_crop(input, indices):\n",
    "    cropped_spectrogram = np.flipud(np.flipud(input)[indices, :])\n",
    "    return cropped_spectrogram\n",
    "\n",
    "colors = ['darkblue','cyan']\n",
    "cmap_masks = plt.cm.colors.ListedColormap(colors)\n",
    "exp_patterns = ['supervised', 'test_finetune']\n",
    "def plot_valid_predictions(indices,                       # three sample indices\n",
    "                           images,                        # shape (N, 1, H, W) or (N, H, W)\n",
    "                           masks_true,                    # shape (N, H, W)\n",
    "                           all_pred_masks,                # dict: name -> np.ndarray (N, H, W)\n",
    "                           save_dir=\"results\",\n",
    "                           trim_rows=17,\n",
    "                           vmin=0.25, vmax=0.75,\n",
    "                           cmap_masks=\"tab20\"):\n",
    "    \"\"\"\n",
    "    Draws one row per index: raw image | GT mask | one column per model prediction.\n",
    "    Saves each figure as results/whale_predictions_<idx>.png and shows it.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Ensure images are 3‑D (N, H, W) for imshow.\n",
    "    if images.ndim == 4:          # (N, C, H, W)\n",
    "        images = images.squeeze(1)  # assume single‑channel\n",
    "    images = images[ :, :-trim_rows, :-4]\n",
    "    masks_true = masks_true[:, :-trim_rows, :-4]\n",
    "    model_names = list(all_pred_masks.keys())\n",
    "    n_cols      = 2 + len(model_names)\n",
    "    n_rows      = len(indices)\n",
    "    spec_frequencies = np.linspace(1.01, 50.0, 399)\n",
    "    freq_mask = (spec_frequencies >= 15) & (spec_frequencies <= 19)\n",
    "    freq_indices = np.where(freq_mask)[0]\n",
    "    cropped_frequencies = spec_frequencies[freq_indices][::-1]\n",
    "\n",
    "    for idx in indices:\n",
    "        fig, axs = plt.subplots(1, n_cols,\n",
    "                                figsize=(3 * n_cols, 2),\n",
    "                                constrained_layout=True)\n",
    "\n",
    "        # --- column 0: raw spectrogram ----------------------------------------------------------\n",
    "        image = images[idx]\n",
    "        image = apply_crop(image, freq_indices)\n",
    "\n",
    "        axs[0].imshow(image, aspect=\"auto\",\n",
    "                      cmap=\"jet\", vmin=vmin, vmax=vmax)\n",
    "\n",
    "        # --- column 1: ground‑truth mask --------------------------------------------------------\n",
    "        mask_true = apply_crop(masks_true[idx], freq_indices)\n",
    "        axs[1].imshow(mask_true, aspect=\"auto\",\n",
    "                      cmap=cmap_masks)\n",
    "\n",
    "        # --- remaining columns: one per model ---------------------------------------------------\n",
    "        for j, name in enumerate(model_names, start=2):\n",
    "            pred_mask = all_pred_masks[name][idx][:-trim_rows, :-4]\n",
    "            pred_mask = apply_crop(pred_mask, freq_indices)\n",
    "            axs[j].imshow(pred_mask,\n",
    "                          aspect=\"auto\", cmap=cmap_masks)\n",
    "\n",
    "        # cosmetic: hide spines / ticks except first column’s y‑ticks\n",
    "        for j, ax in enumerate(axs):\n",
    "            if j != 0:  # hide everything for masks/preds\n",
    "                ax.set_xticks([]); ax.set_xticklabels([])\n",
    "                ax.set_yticks([]); ax.set_yticklabels([])\n",
    "                ax.axis(\"off\")\n",
    "            else:       # first column keeps y‑ticks for context\n",
    "                major_tick_positions = []\n",
    "                major_tick_freqs = [16, 18]\n",
    "                for freq in major_tick_freqs:\n",
    "                    # This finds the index in the array where the value is nearest to `freq`\n",
    "                    closest_index = np.abs(cropped_frequencies - freq).argmin()\n",
    "                    major_tick_positions.append(closest_index)\n",
    "\n",
    "                # 3. Set the major ticks at the found positions with the desired labels\n",
    "                ax.set_yticks(major_tick_positions)\n",
    "                ax.set_yticklabels(major_tick_freqs)\n",
    "\n",
    "                # 4. Turn on automatic minor ticks\n",
    "                # Matplotlib will now add unlabeled ticks between your major ones.\n",
    "                ax.minorticks_on()\n",
    "\n",
    "                # You can keep your existing lines to hide the x-ticks\n",
    "                ax.set_xticks([])\n",
    "                ax.set_xticklabels([])\n",
    "\n",
    "        # save & show ---------------------------------------------------------------------------\n",
    "        out_path = os.path.join(save_dir, f\"whale_predictions_{idx}.png\")\n",
    "        plt.savefig(out_path, dpi=300, transparent=True)\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "images_cpu = valid_dataset_batch[0].cpu().numpy()\n",
    "masks_cpu  = valid_dataset_batch[1].cpu().numpy()\n",
    "import scienceplots\n",
    "\n",
    "with plt.style.context(['science']):\n",
    "    plot_valid_predictions(indices=[4, 8, 25, 36, 101],\n",
    "                        images=images_cpu,\n",
    "                        masks_true=masks_cpu,\n",
    "                        all_pred_masks=all_pred_masks,\n",
    "                        cmap_masks=cmap_masks,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reverb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
